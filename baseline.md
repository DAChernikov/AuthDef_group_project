# Постоение бейзлайна

Расчет бейзлайна приведен в notebooks/baseline_notebook.ipynb.

Для преобразования текстовых данных в числовую форму применен подход Bag of Words (BoW) с помощью CountVectorizer. Учитываются униграммы и биграммы, максимум 500 признаков. BoW выбран как самый очевидный метод.

Тренировочная и тестовая выборки разделены как 20% на 80% случайным образом.

В качестве моделей использовались:
- SVC (Support Vector Classifier) - метод опорных векторов. Нахождение гиперплоскости, максимально разделяющей данные классов. Расстояние от гиперплоскости до ближайших точек классов называется margin. SVM оптимизирует гиперплоскость, чтобы максимизировать этот margin.
- LogisticRegression - логистическая регрессия.
- DecisionTreeClassifier - дерево решений. Модель машинного обучения, которая разбивает данные на подмножества на основе заданных условий, чтобы прийти к какому-либо заключению.

# Метрики качества

Использовались следующие метрики:
- Accuracy. Подходит, если данные сбалансированы (классы примерно равны по численности). К сожалению, это не наш случай.
- Precision. Доля правильных предсказаний среди всех текстов, предсказанных как принадлежащие данному автору.
- Recall. Доля текстов, принадлежащих автору, которые модель смогла правильно классифицировать.
- F1-Score. Гармоническое среднее Precision и Recall.
- Confusion Matrix. Позволяет понять, где именно модель ошибается (между какими авторами происходит путаница).

Accuracy приведена как самая популярная метрика, показавшая результат, похожий на остальные. Но она не рекомендуется для случаев, когда данные не сбалансированы по классам (авторы имеют различное количество текстов). 

Precision, Recall и F1 являются "стандартными" длдя подобного рода задач. 

Confusion Matrix очень наглядна и позволяет изучить результаты детальней.

Метрики приведены в notebooks/baseline_notebook.ipynb для всех трех моделей. Также приведен classification_report для каждого автора.
