# Отчет об экспериментах с DL

## 1. Базовый подход

Базовая модель была построена на классическом ML:
- **Модель**: логистическая регрессия, XGBoost
- **Признаки**: эвристики, TF-IDF, средние Word2Vec-вектора

Лучшие результаты:
- **XGBoost (эвристики + Word2Vec)**:  
  - F1-мера: **~90%**  
  - Accuracy: **~90%**

## 2. Простые DL-модели

В рамках экспериментов с простыми DL-моделями были протестированы базовые архитектуры нейронных сетей:

| Модель  | F1-мера | Accuracy | Комментарий                         |
|---------|--------|--------|-------------------------------------|
| FF-Net  | ~76–78% | ~75%   | Полносвязная сеть на эвристиках + Word2Vec |
| TF-MLP  | ~86.6% | ~86.7% | Аналогично, но на Keras             |
| Bi-LSTM | ~76%   | ~75%   | Учитывает порядок слов              |
| RCNN    | ~81.5% | —      | Лучший из RNN-подходов              |

**Вывод**: простые DL-модели уже могут "догнать" классические подходы, особенно при использовании Keras MLP или RCNN.

## 3. BERT + XGBoost

- Использовались эмбеддинги [CLS] токена из BERT
- Классификатор: XGBoost

Результаты:
- F1-мера: **0.613**
- Accuracy: **0.622**

**Вывод**: использование только [CLS]-токена не дало преимуществ. Модель сильно уступает нашей XGBoost и даже простым DL-подходам.

## 4. Fine-Tuning BERT (DeepPavlov/rubert-base-cased)

- Использовался полный fine-tuning модели RuBERT
- Применены техники регуляризации, OneCycleLR, ранняя остановка

Результаты:
- F1-мера: **~90%**
- График функции потерь показывает устойчивое обучение

**Вывод**: эта модель показывает **лучшее качество** среди всех рассмотренных DL-моделей, сравнимое с лучшим результатом XGBoost, при этом использует только исходный текст.

---

## Общая сводка

| Подход                 | F1-мера | Accuracy | Примечание |
|------------------------|------|----------|------------|
| XGBoost (baseline)     | 0.90 | 0.90     | Лучший из классических |
| TF-MLP (DL)            | 0.866 | 0.867    | Простой нейросетевой подход |
| RCNN (DL)              | 0.815 | —        | Лучшая RNN-модель |
| BERT + XGB             | 0.613 | 0.622    | Низкое качество, только CLS |
| Fine-tuned BERT        | ~0.90 | —        | Лучший DL-подход |

## Заключение

- **Fine-tuned BERT** и **XGBoost** на комбинированных признаках дают наилучшие результаты.
- **BERT + XGB** на основе только [CLS] признака — наименее эффективный.
- Промежуточные DL-модели (**FF-Net**, **BiLSTM**, **RCNN**) дают достойный результат, но уступают Fine-tuned BERT и XGBoost.
